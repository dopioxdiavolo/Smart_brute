#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ –º–æ–¥–µ–ª–∏
"""

import requests
import argparse
import json
import time
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any


def load_wordlist(file_path: str) -> List[str]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è –ø—É—Ç–µ–π"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        # –ë–∞–∑–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        return [
            'admin', 'login', 'user', 'api', 'config', 'dashboard',
            'profile', 'settings', 'logout', 'register', 'auth',
            'users', 'accounts', 'account', 'signin', 'signup',
            'index', 'home', 'main', 'root', 'private', 'public',
            'secret', 'hidden', 'backup', 'test', 'debug', 'dev',
            'configuration', 'management', 'panel', 'control'
        ]


def scan_path(base_url: str, path: str, timeout: int = 10) -> Dict[str, Any]:
    """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –ø—É—Ç–∏"""
    url = f"{base_url.rstrip('/')}/{path.lstrip('/')}"
    
    try:
        response = requests.get(url, timeout=timeout, allow_redirects=False)
        
        return {
            'url': url,
            'path': path,
            'status_code': response.status_code,
            'response_time': response.elapsed.total_seconds(),
            'content_length': len(response.content),
            'headers': dict(response.headers),
            'anomaly_type': classify_anomaly(response),
            'features': extract_features(response, path),
            'predicted_techniques': generate_techniques(response, path),
            'applied_techniques': [],
            'success': False
        }
    except Exception as e:
        return {
            'url': url,
            'path': path,
            'status_code': 0,
            'response_time': 0,
            'content_length': 0,
            'headers': {},
            'anomaly_type': 'ERROR',
            'features': {'error': str(e)},
            'predicted_techniques': [],
            'applied_techniques': [],
            'success': False
        }


def classify_anomaly(response: requests.Response) -> str:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–∏"""
    if response.status_code in [301, 302, 303, 307, 308]:
        return 'REDIRECT_ANOMALY'
    elif response.status_code == 429:
        return 'RATE_LIMIT_ANOMALY'
    elif response.status_code in [401, 403]:
        return 'AUTH_ANOMALY'
    elif response.status_code in [500, 502, 503, 504]:
        return 'SERVER_ERROR'
    elif response.status_code == 200:
        return 'SUCCESS'
    else:
        return 'STATUS_ANOMALY'


def extract_features(response: requests.Response, path: str) -> Dict[str, Any]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    return {
        'status': response.status_code,
        'size': len(response.content),
        'response_time_ms': response.elapsed.total_seconds() * 1000,
        'depth': path.count('/'),
        'path_length': len(path),
        'has_extension': '.' in path,
        'retry_after_seconds': 0,
        'content_type': response.headers.get('content-type', ''),
        'server': response.headers.get('server', ''),
        'encoding_type': response.encoding or 'utf-8',
        'error_message': 'none'
    }


def generate_techniques(response: requests.Response, path: str) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏"""
    techniques = []
    
    if response.status_code in [401, 403]:
        techniques.extend(['TB_AUTH_ATTEMPT', 'TB_HEADER_BYPASS'])
    elif response.status_code in [301, 302]:
        techniques.append('TB_REDIRECT_FOLLOW')
    elif response.status_code in [500, 502, 503]:
        techniques.extend(['TB_NGINX_BYPASS', 'TB_PARAMETER_INJECTION'])
    elif response.status_code == 200:
        techniques.extend(['TB_PATH_VARIATION', 'TB_PARAM_FUZZ'])
    
    return techniques


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–ü—Ä–æ—Å—Ç–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('url', help='URL –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è')
    parser.add_argument('--max-paths', type=int, default=50, help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É—Ç–µ–π')
    parser.add_argument('--delay', type=float, default=0.1, help='–ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏')
    parser.add_argument('--threads', type=int, default=10, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤')
    parser.add_argument('--timeout', type=int, default=10, help='–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞')
    parser.add_argument('--output', default='scan_results.json', help='–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è')
    parser.add_argument('--wordlist', default='wordlists.txt', help='–§–∞–π–ª —Å–ª–æ–≤–∞—Ä—è')
    
    args = parser.parse_args()
    
    print(f"üîç –ü—Ä–æ—Å—Ç–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: {args.url}")
    print(f"üìä –ú–∞–∫—Å–∏–º—É–º –ø—É—Ç–µ–π: {args.max_paths}")
    print(f"‚è±Ô∏è  –ó–∞–¥–µ—Ä–∂–∫–∞: {args.delay}—Å")
    print(f"üßµ –ü–æ—Ç–æ–∫–æ–≤: {args.threads}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è
    wordlist = load_wordlist(args.wordlist)
    paths_to_scan = wordlist[:args.max_paths]
    
    print(f"üìù –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(paths_to_scan)} –ø—É—Ç–µ–π –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    results = []
    
    # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
    with ThreadPoolExecutor(max_workers=args.threads) as executor:
        future_to_path = {
            executor.submit(scan_path, args.url, path, args.timeout): path
            for path in paths_to_scan
        }
        
        for future in as_completed(future_to_path):
            path = future_to_path[future]
            try:
                result = future.result()
                results.append(result)
                
                # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                status = result['status_code']
                if status == 200:
                    print(f"  üü¢ /{path} [{status}]")
                elif status in [301, 302]:
                    print(f"  üîÑ /{path} [{status}]")
                elif status in [401, 403]:
                    print(f"  üîê /{path} [{status}]")
                elif status in [500, 502, 503]:
                    print(f"  üî¥ /{path} [{status}]")
                else:
                    print(f"  ‚ö™ /{path} [{status}]")
                
                # –ó–∞–¥–µ—Ä–∂–∫–∞
                if args.delay > 0:
                    time.sleep(args.delay)
                    
            except Exception as e:
                print(f"  ‚ùå /{path} - –û—à–∏–±–∫–∞: {e}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {args.output}")
    print(f"üìä –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {len(results)} –ø—É—Ç–µ–π")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    status_counts = {}
    for result in results:
        status = result['status_code']
        status_counts[status] = status_counts.get(status, 0) + 1
    
    print("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç–∞—Ç—É—Å-–∫–æ–¥–∞–º:")
    for status, count in sorted(status_counts.items()):
        print(f"  {status}: {count} –ø—É—Ç–µ–π")


if __name__ == '__main__':
    main() 